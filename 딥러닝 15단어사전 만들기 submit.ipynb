{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efbc9ad",
   "metadata": {},
   "source": [
    "# KoNLPY  중 MeCab 클래스 실습환경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfea056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs('자연어처리가너무재밌어서밥먹는것도가끔까먹어요'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abccc360",
   "metadata": {},
   "source": [
    "# 15-2.  데이터 다운로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81369e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6b5ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2adf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in raw:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725e0622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ade5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 11\n",
      "Outlier Index: 19\n",
      "Outlier Index: 21\n"
     ]
    }
   ],
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장의 수가 1500을 초과하는 문장 길이를 추출합니다.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e871a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라고 조던이 말했다.\n",
      "- 모르고 있습니다.\n",
      "- 네, 보이는군요.\n",
      "디즈니사만이 아니다.\n",
      "큰 파티는 아니지요.\n",
      "의자는 비어 있었다.\n",
      "이 일은 계속됩니다.\n",
      "나는 크게 실망했다.\n",
      "그 이유는 간단하다.\n",
      "이력서와 자기 소개서\n",
      "시대가 변하고 있다.\n",
      "는 돌발질문을 했다.\n",
      "9. 몇 분간의 명상\n",
      "하와이, 빅 아일랜드\n",
      "키스를 잘 하는 방법\n",
      "키스를 잘 하는 방법\n",
      "스피어스가 뚱뚱한가?\n",
      "산 위를 나는 느낌.\n",
      "세 시간쯤 걸었을까?\n",
      "(아직 읽고있습니까?\n",
      "처음에는 장난이었다.\n",
      "우리는 운이 좋았다.\n",
      "아기가 숨을 멈출 때\n",
      "건물 전체 무너져내려\n",
      "그녀의 아름다운 눈.\n",
      "대답은 다음과 같다.\n",
      "\"사과할 것이 없다.\n",
      "폭탄테러가 공포 유발\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "조금은 새침한 샬롯？\n",
      "조금은 새침한 샬롯？\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7fef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 77591\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c4fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaRUlEQVR4nO3dfZRcdZ3n8fdHkOeZBEgmhnS045DBDRwfsJUwuCPHOJDwFNejbBhWA2RPlj3ooOJAAntEXR9gZMEwizgZgoDDBBgUiRjFTMAz6zhk7KBAMEZaCKRDIA0kgOADke/+cX9lKpXqdHVVddWtup/XOXW67u/e+t1v3+763t/93lu3FBGYmVkxvKbdAZiZWes46ZuZFYiTvplZgTjpm5kViJO+mVmBOOmbmRWIk75Zk0nqlRSS9m5in2dK+n4T+3tY0vHp+acl/WMT+75Y0nXN6s+ay0m/y0l6l6QfSXpe0nOS/k3SO5rQ71mSftiMGJtJ0kZJ7+2kdUq6QdLvJL2YHuskfVHSuNIyEXFzRJxQY1+fG2m5iDgyIn5Qb8xl6zte0mBF31+IiP/eaN82Npz0u5ikPwbuAv4OOASYAnwG+G0747Kq/jYi/giYCJwNzAT+TdKBzVxJM48+rDM56Xe3PwOIiOUR8fuI+HVEfD8iHiwtIOkcSeslbZN0t6Q3lM0LSedKekTSdknXKPOfgK8Cx0r6laTtafl9JV0h6QlJT0v6qqT907zjJQ1KukDSVklbJJ1dtq79Jf0fSY+no5Iflr12Zjpa2S7pgVJZYjQkvUbSIkm/lPSspNskHZLmlcox81Psz0i6pCK2G9M2Wi/pwtLoVtLXgdcD307b4sKy1Z5Zrb89iYjfRMSPgdOAQ8l2ALscWaW/wVVpO74g6SFJR0laCJwJXJhi+XZafqOkiyQ9CLwkae8qRyf7Sbo1HWncL+ktZb9/SDq8bPoGSZ9LO6TvAoel9f1K0mGqKBdJOk1ZOWm7pB+k/5/SvI2SPinpwfR3v1XSfrVsK6uPk353+wXw+5Sw5kg6uHympLnAxcD7yUaY/w9YXtHHKcA7gDcDpwMnRsR64Fzg3yPioIgYn5a9jGxH81bgcLIji0+V9fU6YFxqXwBcUxbTFcDbgT8nOyq5EHhV0hTgO8DnUvsngW9ImjjKbfFR4H3Au4HDgG3ANRXLvAs4ApgFfKosOV0K9AJvBP4S+G+lF0TEh4AngFPTtvjbGvobUUS8CKwC/nOV2ScAf0G2rceR/V2ejYilwM1kRw0HRcSpZa85AzgZGB8RO6r0ORf4Z7Jt/E/AtyS9doQYXwLmAE+m9R0UEU+WLyPpz8j+pz5G9j+2kmwHuU/ZYqcDs4FpZP9nZ+1pvdYYJ/0uFhEvkCWeAP4BGJK0QtKktMi5wBcjYn1KBF8A3lo+2gcui4jtEfEEcC9ZQt+NJAELgY9HxHMpaX0BmFe22CvAZyPilYhYCfwKOELSa4BzgPMjYnM6KvlRRPyWLMGujIiVEfFqRKwC+oGTRrk5zgUuiYjB1O+ngQ9o13LHZ9LR0APAA0BptHs68IWI2BYRg8DVNa5zuP5q9SRZEq70CvBHwJsApb/flhH6ujoiNkXEr4eZvzYibo+IV4Argf3ISkyN+q/AdyJiVer7CmB/sp17eWxPRsRzwLcZ5n/MmsNJv8ulhHBWRPQAR5GNcr+cZr8BWJIOu7cDzwEiG4mXPFX2/GXgoGFWNRE4AFhb1t/3UnvJsxWjzFJ/E8iSzC+r9PsG4IOlPlO/7wIm7+n3HqafO8r6WA/8HphUtsxwv+thwKayeeXP96TWbTecKWR/k11ExD3A/yU7Utkqaamy8zd7MlLMf5gfEa8Cg2S/d6MOAx6v6HsT9f2PWRM46RdIRPwcuIEs+UP25vsfETG+7LF/RPyolu4qpp8Bfg0cWdbXuIio5Q38DPAb4E+rzNsEfL0ixgMj4rIa+q3sZ05FP/tFxOYaXrsF6Cmbnloxv+m3qpV0EPBespLbbiLi6oh4OzCDrMzzNyPEMlKMf/id0pFXD9mRBmSJ+ICyZV83in6fJNvhlvpWWlct293GgJN+F5P0pnTitCdNTyWr7d6XFvkqsFjSkWn+OEkfrLH7p4GeUm02jeD+AbhK0p+k/qZIOnGkjtJrrweuTCcC95J0rKR9gX8ETpV0YmrfT9lJ4Z49dPnatFzpsXf6XT9fKl1JmpjOadTiNrLtdHA6x/CRKtvijTX2tUfKToa/HfgW2XmHr1VZ5h2Sjkk195fIdpivNhjL2yW9P22rj5Fd4VX6P/kp8Fdp+88mOy9S8jRwqMouL61wG3CypFkp3gtS37UMLGwMOOl3txeBY4A1kl4iexOvI3vjERF3AJcDt0h6Ic2bU2Pf9wAPA09Jeia1XQQMAPel/v6F7ERmLT4JPAT8mKykcTnwmojYRHaS8WJgiGzE/jfs+X93JdlRR+nxaWAJsAL4vqQXybbFMTXG9lmycsdj6Xe6nV0ve/0i8L9S6eiTNfZZ6cIU17PATcBa4M/TydJKf0y2g91GVjp5FvhSmrcMmJFi+dYo1n8nWf19G/Ah4P2pBg9wPnAqsJ3s6qA/9JuOHpcDj6Z17lISiogNZOdl/o7siO5UspPevxtFbNZE8peomI2OpP8JzIuId4+4sFnOeKRvNgJJkyUdp+xa/yPIjpTuaHdcZvXwp/PMRrYP8Pdk15FvB24BvtLOgMzq5fKOmVmBuLxjZlYguS7vTJgwIXp7e9sdhplZR1m7du0zEVH1ViW5Tvq9vb309/e3Owwzs44i6fHh5rm8Y2ZWIE76ZmYF4qRvZlYgTvpmZgXipG9mViBO+mZmBeKkb2ZWIE76ZmYF4qRvZlYgTvqWa72LvkPvou+0OwyzruGkb2ZWICMmfUnXS9oqaV1Z25ck/VzSg5LukDS+bN5iSQOSNpR/P6qk2altQNKipv8mZhV8lGC2u1pG+jcAsyvaVgFHRcSbgV8AiwEkzQDmAUem13wlfZnyXsA1ZN+/OgM4Iy1r1hRO8Ga1GTHpR8S/kn1RdXnb9yNiR5q8D+hJz+cCt0TEbyPiMbIvyX5negxExKPpC5FvScua1cRJ3aw5mlHTPwf4bno+BdhUNm8wtQ3XvhtJCyX1S+ofGhpqQnjWCZzUzVqjofvpS7oE2AHc3JxwICKWAksB+vr6/F2OXa7RRF/5eu84zPas7qQv6SzgFGBW7Pyi3c3A1LLFelIbe2g3+4NS0t542ck1LWdmo1NX0pc0G7gQeHdEvFw2awXwT5KuBA4DpgP/AQiYLmkaWbKfB/xVI4FbZ3PSNmuPEZO+pOXA8cAESYPApWRX6+wLrJIEcF9EnBsRD0u6DfgZWdnnvIj4fernI8DdwF7A9RHx8Bj8PmZmtgcjJv2IOKNK87I9LP954PNV2lcCK0cVndkYqrWUZNZN/IlcM7MCcdI3MysQJ30zswJp6Dp9s1bzVT9mjfFI37qeP+1rtpOTvplZgTjpm5kViGv6lksux5iNDY/0zcwKxEnfzKxAXN6xlnLZxqy9PNI3MysQJ30rDF+vbwba+f0n+dPX1xf9/f3tDsOaoBOSre+2ad1C0tqI6Ks2zyN9M7MC8YlcG1OdMMIv8f31rQg80jczKxAnfWsKnyQ16wxO+mZmBeKkbzYMH71YN/KJXBsTTpZm+eSRvplZgXikb03lEb5Zvjnpm1Xwjsu6mcs7Vhef5DTrTCMmfUnXS9oqaV1Z2yGSVkl6JP08OLVL0tWSBiQ9KOnostfMT8s/Imn+2Pw6ZmPHOzrrBrWM9G8AZle0LQJWR8R0YHWaBpgDTE+PhcC1kO0kgEuBY4B3ApeWdhRmZtY6I9b0I+JfJfVWNM8Fjk/PbwR+AFyU2m+K7Nad90kaL2lyWnZVRDwHIGkV2Y5keeO/grWTR75mnaXemv6kiNiSnj8FTErPpwCbypYbTG3Dte9G0kJJ/ZL6h4aG6gzPzMyqafjqnYgISU27KX9ELAWWQnY//Wb1a83hkb1ZZ6t3pP90KtuQfm5N7ZuBqWXL9aS24drNzKyF6k36K4DSFTjzgTvL2j+cruKZCTyfykB3AydIOjidwD0htVmH8JUrZt1hxPKOpOVkJ2InSBokuwrnMuA2SQuAx4HT0+IrgZOAAeBl4GyAiHhO0v8GfpyW+2zppK7lmxP97iq3ib90xTpJLVfvnDHMrFlVlg3gvGH6uR64flTRmeWAd3zWTfyJXDOzAnHSNzMrECd9M7MCcdI3MysQ31rZqvLJS7Pu5JG+mVmBOOmbmRWIk76ZWYE46ZuZFYiTvgG+t45ZUTjpmzWJd5zWCZz0zcwKxEnfzKxAnPTNzArESd+syVzbtzzzbRgKzsnJrFic9M0a5B2ndRKXd8zMCsRJ38ysQJz0zcwKxEnfzKxAnPTNxpgv4bQ88dU7ZmPEid7yyEnfduFEZdbdGirvSPq4pIclrZO0XNJ+kqZJWiNpQNKtkvZJy+6bpgfS/N6m/AZmHcJlHsuDupO+pCnAXwN9EXEUsBcwD7gcuCoiDge2AQvSSxYA21L7VWk5MzNroUZP5O4N7C9pb+AAYAvwHuD2NP9G4H3p+dw0TZo/S5IaXL+ZmY1C3Uk/IjYDVwBPkCX754G1wPaI2JEWGwSmpOdTgE3ptTvS8odW9itpoaR+Sf1DQ0P1hmdmZlU0Ut45mGz0Pg04DDgQmN1oQBGxNCL6IqJv4sSJjXZnZmZlGinvvBd4LCKGIuIV4JvAccD4VO4B6AE2p+ebgakAaf444NkG1m9mZqPUyCWbTwAzJR0A/BqYBfQD9wIfAG4B5gN3puVXpOl/T/PviYhoYP3WAF9FYlZMjdT015CdkL0feCj1tRS4CPiEpAGymv2y9JJlwKGp/RPAogbiNjOzOjT04ayIuBS4tKL5UeCdVZb9DfDBRtZnZmaN8b13zMwKxEnfzKxAnPTNWqzydgy+PYO1kpO+mVmB+C6bBeMRpVmxeaRvZlYgHumbtYmPuqwdPNI3MysQJ30zswJx0u8yvvzPzPbESb/LeSdgZuWc9M3MCsRJ38ysQHzJZkG4xGNm4JG+mVmhOOmbmRWIk76ZWYG4pm+WE5XnXTZednKbIrFu5pG+WU75MxY2FjzS71JOFmZWjUf6ZmYF4qRvZlYgTvpmHco1f6uHk75Zzjm5WzM56ZuZFUhDV+9IGg9cBxwFBHAOsAG4FegFNgKnR8Q2SQKWACcBLwNnRcT9jazfdvJIsPv5b2zN0OhIfwnwvYh4E/AWYD2wCFgdEdOB1WkaYA4wPT0WAtc2uG4zMxulupO+pHHAXwDLACLidxGxHZgL3JgWuxF4X3o+F7gpMvcB4yVNrnf9ZmY2eo2M9KcBQ8DXJP1E0nWSDgQmRcSWtMxTwKT0fAqwqez1g6ltF5IWSuqX1D80NNRAeGZmVqmRmv7ewNHARyNijaQl7CzlABARISlG02lELAWWAvT19Y3qtUXjGq+ZjVYjI/1BYDAi1qTp28l2Ak+Xyjbp59Y0fzMwtez1PanNzMxapO6kHxFPAZskHZGaZgE/A1YA81PbfODO9HwF8GFlZgLPl5WBzMysBRq94dpHgZsl7QM8CpxNtiO5TdIC4HHg9LTsSrLLNQfILtk8u8F1mxk7y3y+FbPVoqGkHxE/BfqqzJpVZdkAzmtkfWZm1hh/ItfMrECc9M3MCsRJ38ysQJz0zcwKxF+X2IH8oSwzq5dH+mZdwvfdt1o46ZuZFYiTvplZgbim30F86G618Cd0bU880jczKxAnfTOzAnHSNzMrECd9M7MC8Ylcs4IovxDAJ3mLyyN9sy7lD2tZNU76ZmYF4qRvZlYgrul3AB+im1mzOOnnkJO8mY0Vl3fMzArEI32zLucjRyvnkb6ZWYE46ZuZFYjLOzniw3AzG2sNj/Ql7SXpJ5LuStPTJK2RNCDpVkn7pPZ90/RAmt/b6LrNrD7+tG5xNaO8cz6wvmz6cuCqiDgc2AYsSO0LgG2p/aq0nJmZtVBDSV9SD3AycF2aFvAe4Pa0yI3A+9LzuWmaNH9WWt7MzFqk0ZH+l4ELgVfT9KHA9ojYkaYHgSnp+RRgE0Ca/3xa3szMWqTuE7mSTgG2RsRaScc3KyBJC4GFAK9//eub1W2uubZq7VL5v+dbLne/Rkb6xwGnSdoI3EJW1lkCjJdU2pn0AJvT883AVIA0fxzwbGWnEbE0Ivoiom/ixIkNhGdmZpXqTvoRsTgieiKiF5gH3BMRZwL3Ah9Ii80H7kzPV6Rp0vx7IiLqXb+ZmY3eWHw46yLgE5IGyGr2y1L7MuDQ1P4JYNEYrNvMzPZAeR5s9/X1RX9/f7vDGDOu5Vteubbf2SStjYi+avN8GwYzswJx0jczKxAnfTPbjW/T0L2c9M3MCsRJ38yG5RF/93HSNzMrECd9M7MCcdI3MysQJ30zG5Fr+93DSd/MrECc9M2sZh7xdz5/MXoL+c1iZu3mkb6ZWYE46ZuZFYiTvplZgTjpm5kViJO+mVmBOOmPIV/eZt3K/9udy0nfzKxAnPTNrGEe+XcOJ30zswLxJ3JbwCMgM8sLJ30zq5sHNJ3H5R0zaxrX9vPPSd/MrEDqLu9ImgrcBEwCAlgaEUskHQLcCvQCG4HTI2KbJAFLgJOAl4GzIuL+xsI3szyqHO1vvOzkNkVilRoZ6e8ALoiIGcBM4DxJM4BFwOqImA6sTtMAc4Dp6bEQuLaBdZuZWR3qHulHxBZgS3r+oqT1wBRgLnB8WuxG4AfARan9pogI4D5J4yVNTv10Fdc0zXZVek+URvyV09Y6TanpS+oF3gasASaVJfKnyMo/kO0QNpW9bDC1Vfa1UFK/pP6hoaFmhGdmZknDSV/SQcA3gI9FxAvl89KoPkbTX0QsjYi+iOibOHFio+GZWQfwVT+t09B1+pJeS5bwb46Ib6bmp0tlG0mTga2pfTMwtezlPanNzArCib396h7pp6txlgHrI+LKslkrgPnp+XzgzrL2DyszE3i+G+v5ZmZ51shI/zjgQ8BDkn6a2i4GLgNuk7QAeBw4Pc1bSXa55gDZJZtnN7BuM+sCHvm3XiNX7/wQ0DCzZ1VZPoDz6l2fmZk1zp/INTMrEN9wrYl8qGpmeeeRvpnlRuWlm76Us/k80jez3KlM9P4Eb/N4pG9mHcMj/8Z5pN8E/ic0aw8fAYyeR/pmZgXipG9mViAu7zTAZR0z6zRO+mbWcTzgqp/LO2bW8Ya7qsdX++zOSd/MrECc9M2sa3hkPzLX9M2s6/gTvcNz0q+DRxJm1qlc3jEzKxCP9GvgQ0Oz7lLtaL30/u7297uT/ii4rGPW2fb0Hi7K+9vlHTOzUej0K4Q80jczq6KTE/ueOOmbmdWh1p1C3s4NuLxjZjaG8lYOctI3M2uBvHz/r8s7ZmZtVJn4x7oc5KRvZtZC7S71tLy8I2m2pA2SBiQtavX6zcyKrKVJX9JewDXAHGAGcIakGa2MwcysyFo90n8nMBARj0bE74BbgLktjsHMrLBaXdOfAmwqmx4EjilfQNJCYGGa/JWkDQ2ucwLwTIN9jKW8xwf5jzHv8YFjbIa8xwdNiFGXNyWONww3I3cnciNiKbC0Wf1J6o+Ivmb112x5jw/yH2Pe4wPH2Ax5jw86I8ZWl3c2A1PLpntSm5mZtUCrk/6PgemSpknaB5gHrGhxDGZmhdXS8k5E7JD0EeBuYC/g+oh4eIxX27RS0RjJe3yQ/xjzHh84xmbIe3zQATEqItodg5mZtYjvvWNmViBO+mZmBdK1ST+Pt3uQNFXSvZJ+JulhSeen9kMkrZL0SPp5cJvj3EvSTyTdlaanSVqTtuWt6SR8O+MbL+l2ST+XtF7SsXnahpI+nv6+6yQtl7Rfu7ehpOslbZW0rqyt6jZT5uoU64OSjm5jjF9Kf+cHJd0haXzZvMUpxg2STmxHfGXzLpAUkiak6bZsw1p0ZdLP8e0edgAXRMQMYCZwXoprEbA6IqYDq9N0O50PrC+bvhy4KiIOB7YBC9oS1U5LgO9FxJuAt5DFmottKGkK8NdAX0QcRXbBwjzavw1vAGZXtA23zeYA09NjIXBtG2NcBRwVEW8GfgEsBkjvm3nAkek1X0nv+1bHh6SpwAnAE2XN7dqGI4uIrnsAxwJ3l00vBha3O64qcd4J/CWwAZic2iYDG9oYUw9ZAngPcBcgsk8Y7l1t27YhvnHAY6SLEMrac7EN2fmp80PIro67CzgxD9sQ6AXWjbTNgL8Hzqi2XKtjrJj3X4Cb0/Nd3tNkVwQe2474gNvJBh8bgQnt3oYjPbpypE/12z1MaVMsVUnqBd4GrAEmRcSWNOspYFK74gK+DFwIvJqmDwW2R8SONN3ubTkNGAK+lkpQ10k6kJxsw4jYDFxBNurbAjwPrCVf27BkuG2W1/fPOcB30/NcxChpLrA5Ih6omJWL+Krp1qSfa5IOAr4BfCwiXiifF9mwoC3X0Uo6BdgaEWvbsf4a7Q0cDVwbEW8DXqKilNPmbXgw2U0EpwGHAQdSpSSQN+3cZrWQdAlZefTmdsdSIukA4GLgU+2OZTS6Nenn9nYPkl5LlvBvjohvpuanJU1O8ycDW9sU3nHAaZI2kt0B9T1k9fPxkkof5Gv3thwEBiNiTZq+nWwnkJdt+F7gsYgYiohXgG+Sbdc8bcOS4bZZrt4/ks4CTgHOTDsnyEeMf0q2c38gvWd6gPslvS4n8VXVrUk/l7d7kCRgGbA+Iq4sm7UCmJ+ezyer9bdcRCyOiJ6I6CXbZvdExJnAvcAH2h0fQEQ8BWySdERqmgX8jJxsQ7KyzkxJB6S/dym+3GzDMsNtsxXAh9MVKDOB58vKQC0laTZZufG0iHi5bNYKYJ6kfSVNIzth+h+tjC0iHoqIP4mI3vSeGQSOTv+judmGu2n3SYWxegAnkZ3t/yVwSbvjSTG9i+wQ+kHgp+lxElndfDXwCPAvwCE5iPV44K70/I1kb6gB4J+Bfdsc21uB/rQdvwUcnKdtCHwG+DmwDvg6sG+7tyGwnOwcwytkyWnBcNuM7OT9Nem98xDZlUjtinGArDZeer98tWz5S1KMG4A57YivYv5Gdp7Ibcs2rOXh2zCYmRVIt5Z3zMysCid9M7MCcdI3MysQJ30zswJx0jczKxAnfTOzAnHSNzMrkP8PYMiReU4gkyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9084d",
   "metadata": {},
   "source": [
    "# 15-3. 공백기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3aa8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):                # corpus: Tokenized Sentence's List \n",
    "    \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbcdef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 3-1\n",
    "# 정제된 데이터 filtered_corpus를 공백 기반으로 토큰화하여 저장하는 코드를 직접 작성해 보세요.\n",
    "split_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "     # 코드를 작성하세요\n",
    "     split_corpus.append(kor.split())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "829afbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Vocab Size: 237435\n"
     ]
    }
   ],
   "source": [
    "split_tensor, split_tokenizer = tokenize(split_corpus)\n",
    "\n",
    "print(\"Split Vocab Size:\", len(split_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c4d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 이\n",
      "1 : 밝혔다.\n",
      "2 : 있다.\n",
      "3 : 말했다.\n",
      "4 : 수\n",
      "5 : 있는\n",
      "6 : 그는\n",
      "7 : 대한\n",
      "8 : 위해\n",
      "9 : 전했다.\n",
      "10 : 지난\n",
      "11 : 이번\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(split_tokenizer.word_index):\n",
    "    print(idx, \":\", word)\n",
    "\n",
    "    if idx > 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b578f7",
   "metadata": {},
   "source": [
    "# 15-4 형태소 기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c833530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 4-1\n",
    "# 위에서 사용한 코드를 활용해 MeCab 단어 사전을 만들어보세요. \n",
    "# Hint : mecab.morphs()를 사용해서 형태소분석을 합니다.\n",
    "\n",
    "def mecab_split(sentence):\n",
    "    # 코드를 작성하세요\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    # 코드를 작성하세요\n",
    "    mecab_corpus.append(mecab_split(kor))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ab5756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab Vocab Size: 52279\n"
     ]
    }
   ],
   "source": [
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a992ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['목격자 의 진술 에 따라 경찰 은 열 명 의 청년 이 세 명 의 북한 사람 을 공격 하 여 그 중 한 명 이 칼 에 찔려 사망 한 것 으로 보 고 있 다 .']\n"
     ]
    }
   ],
   "source": [
    "# 문제 4-2\n",
    "# Case 1 : tokenizer.sequences_to_texts()\n",
    "# 여기에 코드를 작성하세요.\n",
    "\n",
    "\n",
    "print(mecab_tokenizer.sequences_to_texts([mecab_tensor[100]]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c4a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목격자 의 진술 에 따라 경찰 은 열 명 의 청년 이 세 명 의 북한 사람 을 공격 하 여 그 중 한 명 이 칼 에 찔려 사망 한 것 으로 보 고 있 다 . \n"
     ]
    }
   ],
   "source": [
    "# 문제 4-3\n",
    "# Case 2 : tokenizer.index_word\n",
    "# 여기에 코드를 작성하세요.\n",
    "\n",
    "\n",
    "sentence = \"\"\n",
    "\n",
    "for w in mecab_tensor[100]:\n",
    "    if w == 0: continue         \n",
    "    sentence += mecab_tokenizer.index_word[w] + \" \"\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "\n",
    "# =====\n",
    "# mecab_tensor[100]: Mecab 토크나이저로 전처리된 101번째 문장의 Tensor 형태\n",
    "# w == 0: padding 처리된 부분은 무시\n",
    "# mecab_tokenizer.index_word[w]: ID를 실제 단어로 변환\n",
    "# \" \": 단어들 사이에 공백 삽입\n",
    "#sentence: 최종적으로 복원된 원문(또는 형태소 시퀀스)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f6e96",
   "metadata": {},
   "source": [
    "# 프로젝트 루브릭 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0739eae",
   "metadata": {},
   "source": [
    "### 1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?\n",
    "- 말뭉치 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 이루어졌는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9301333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 말뭉치 저장\n",
    "# filtered_corpus를 한 줄씩 저장\n",
    "\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in filtered_corpus:\n",
    "        f.write(line.strip() + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93acc93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 76908 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4996369\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=2161\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 76908 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 175917 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 76908\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 238189\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 238189 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=93619 obj=14.821 num_tokens=522726 num_tokens/piece=5.58355\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=83119 obj=13.4775 num_tokens=525154 num_tokens/piece=6.3181\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=62328 obj=13.517 num_tokens=546427 num_tokens/piece=8.76696\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=62293 obj=13.4741 num_tokens=546849 num_tokens/piece=8.77866\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46715 obj=13.6632 num_tokens=575444 num_tokens/piece=12.3182\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46713 obj=13.6192 num_tokens=575563 num_tokens/piece=12.3213\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=35034 obj=13.8706 num_tokens=606916 num_tokens/piece=17.3236\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=35034 obj=13.8187 num_tokens=606923 num_tokens/piece=17.3238\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=26275 obj=14.1197 num_tokens=639363 num_tokens/piece=24.3335\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26275 obj=14.0626 num_tokens=639415 num_tokens/piece=24.3355\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19706 obj=14.4126 num_tokens=673746 num_tokens/piece=34.1899\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19706 obj=14.3478 num_tokens=673795 num_tokens/piece=34.1924\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14779 obj=14.7467 num_tokens=710406 num_tokens/piece=48.0686\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14779 obj=14.6707 num_tokens=710398 num_tokens/piece=48.0681\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11084 obj=15.1437 num_tokens=748265 num_tokens/piece=67.5086\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11084 obj=15.0557 num_tokens=748653 num_tokens/piece=67.5436\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.4839 num_tokens=780315 num_tokens/piece=88.6722\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.4016 num_tokens=780323 num_tokens/piece=88.6731\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm.vocab\n"
     ]
    }
   ],
   "source": [
    "# 2. SentencePiece 모델 학습\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 학습 실행\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm',\n",
    "    vocab_size=8000,\n",
    "    model_type='unigram',         # 또는 'bpe'\n",
    "    character_coverage=1.0,       # 한글은 1.0 권장\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4837f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 입력 문장: 나는 자연어처리를 공부합니다.\n",
      "🧱 서브워드: ['▁나는', '▁자연', '어', '처', '리', '를', '▁공', '부', '합니다', '.']\n",
      "🔢 토큰 ID: [2027, 2699, 69, 767, 41, 10, 273, 106, 1332, 5]\n",
      "📝 복원된 문장: 나는 자연어처리를 공부합니다.\n"
     ]
    }
   ],
   "source": [
    "# 3: 학습된 모델 로드 및 테스트\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"spm.model\")\n",
    "\n",
    "sample = \"나는 자연어처리를 공부합니다.\"\n",
    "print(\"✅ 입력 문장:\", sample)\n",
    "print(\"🧱 서브워드:\", sp.encode(sample, out_type=str))\n",
    "print(\"🔢 토큰 ID:\", sp.encode(sample, out_type=int))\n",
    "print(\"📝 복원된 문장:\", sp.decode(sp.encode(sample, out_type=int)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2891cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Tensor shape: (76908, 100)\n"
     ]
    }
   ],
   "source": [
    "# 4: 전체 코퍼스 토큰화 → 텐서로 변환\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "token_ids = [sp.encode(line, out_type=int) for line in filtered_corpus]\n",
    "padded_ids = pad_sequences(token_ids, padding='post')\n",
    "\n",
    "print(\"🧾 Tensor shape:\", padded_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e12538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae543bc6",
   "metadata": {},
   "source": [
    "### 2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?\n",
    "- SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda86ab",
   "metadata": {},
   "source": [
    "### 웹에서 실제 데이터셋 사용: 네이버 영화 리뷰 감정 분석 (Naver Sentiment Movie Corpus)\n",
    "\n",
    "https://github.com/e9t/nsmc\n",
    "\n",
    "라벨: 0 = 부정, 1 = 긍정\n",
    "\n",
    "전체 리뷰 텍스트를 SentencePiece로 토큰화하고 분류 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ccb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentencePiece + Text Classification (with NSMC)\n",
    "\n",
    "# Step 1. NSMC 데이터 불러오기\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\"\n",
    "\n",
    "train_df = pd.read_csv(train_url, sep='\\t').dropna()\n",
    "test_df = pd.read_csv(test_url, sep='\\t').dropna()\n",
    "\n",
    "train_texts = train_df['document'].astype(str).tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "test_texts = test_df['document'].astype(str).tolist()\n",
    "test_labels = test_df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ea72e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 149995 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5430559\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=2979\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 149995 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 311082 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 149995\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 357808\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 357808 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=159447 obj=15.4103 num_tokens=842494 num_tokens/piece=5.28385\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=147637 obj=14.3359 num_tokens=847926 num_tokens/piece=5.74332\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=110665 obj=14.4403 num_tokens=883721 num_tokens/piece=7.98555\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=110479 obj=14.3843 num_tokens=884257 num_tokens/piece=8.00385\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=82857 obj=14.6248 num_tokens=929158 num_tokens/piece=11.214\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82849 obj=14.5613 num_tokens=929278 num_tokens/piece=11.2165\n",
      "unigram_model_trainer.cc(505) LOG(I"
     ]
    }
   ],
   "source": [
    "# Step 2. corpus.txt 저장 후 SentencePiece 학습\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in train_texts:\n",
    "        f.write(line.strip() + \"\\n\")\n",
    "        \n",
    "        \n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm',\n",
    "    vocab_size=8000,\n",
    "    model_type='unigram',\n",
    "    character_coverage=1.0,\n",
    "    pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c7cb02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NFO) EM sub_iter=0 size=62136 obj=14.8286 num_tokens=971838 num_tokens/piece=15.6405\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=62134 obj=14.7674 num_tokens=971875 num_tokens/piece=15.6416\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46600 obj=15.0649 num_tokens=1017777 num_tokens/piece=21.8407\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46600 obj=14.9994 num_tokens=1017773 num_tokens/piece=21.8406\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34950 obj=15.335 num_tokens=1065519 num_tokens/piece=30.487\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34950 obj=15.266 num_tokens=1065518 num_tokens/piece=30.4869\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=26212 obj=15.6388 num_tokens=1115420 num_tokens/piece=42.5538\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26212 obj=15.5631 num_tokens=1115434 num_tokens/piece=42.5543\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19659 obj=15.9763 num_tokens=1169225 num_tokens/piece=59.4753\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19659 obj=15.8901 num_tokens=1169238 num_tokens/piece=59.476\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14744 obj=16.3483 num_tokens=1226829 num_tokens/piece=83.2087\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14744 obj=16.2475 num_tokens=1226874 num_tokens/piece=83.2117\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11058 obj=16.78 num_tokens=1291216 num_tokens/piece=116.768\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11058 obj=16.6633 num_tokens=1291247 num_tokens/piece=116.77\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=17.1474 num_tokens=1346923 num_tokens/piece=153.059\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=17.0423 num_tokens=1347400 num_tokens/piece=153.114\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm.vocab\n"
     ]
    }
   ],
   "source": [
    "# Step 3. 토크나이저 로드 및 문장 → 시퀀스 변환\n",
    "import sentencepiece as spm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"spm.model\")\n",
    "\n",
    "X_train = [sp.encode(line, out_type=int) for line in train_texts]\n",
    "X_test = [sp.encode(line, out_type=int) for line in test_texts]\n",
    "\n",
    "maxlen = 50\n",
    "X_train_pad = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a4df47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 22s 3ms/step - loss: 0.4280 - accuracy: 0.8014 - val_loss: 0.3500 - val_accuracy: 0.8500\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3345 - accuracy: 0.8559 - val_loss: 0.3436 - val_accuracy: 0.8532\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3207 - accuracy: 0.8608 - val_loss: 0.3418 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3098 - accuracy: 0.8651 - val_loss: 0.3443 - val_accuracy: 0.8486\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2996 - accuracy: 0.8684 - val_loss: 0.3477 - val_accuracy: 0.8479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x76bd6b8e8e20>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4. 모델 구성 및 학습\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# numpy 배열로 변환 (오류 방지)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=maxlen),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_pad, train_labels, epochs=5, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fd62134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3619 - accuracy: 0.8417\n",
      "✅ Test Accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "# Step 5. 평가\n",
    "loss, acc = model.evaluate(X_test_pad, test_labels)\n",
    "print(f\"✅ Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0603d",
   "metadata": {},
   "source": [
    "###  루브릭 2번 항목 충족 여부\n",
    "\n",
    "- SentencePiece 토크나이저로 NSMC 감성 데이터셋을 서브워드 단위로 변환하였고,\n",
    "- 변환된 텍스트를 기반으로 딥러닝 분류 모델을 학습하였으며,\n",
    "- 모델은 정상적으로 수렴하여 **Test Accuracy가 80% 이상**임을 확인하였다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6f20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd2f711d",
   "metadata": {},
   "source": [
    "### 3. SentencePiece의 성능을 다각도로 비교분석하였는가?\n",
    "- SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b607c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1. 데이터 불러오기 (NSMC)\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", sep='\\t').dropna()\n",
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", sep='\\t').dropna()\n",
    "\n",
    "train_texts = train_df['document'].astype(str).tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "test_texts = test_df['document'].astype(str).tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "639531d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2. corpus.txt 저장\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in train_texts:\n",
    "        f.write(line.strip() + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "834da5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 149995 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5430559\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=2979\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 149995 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 311082 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 149995\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 357808\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 357808 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=159447 obj=15.4103 num_tokens=842494 num_tokens/piece=5.28385\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=147637 obj=14.3359 num_tokens=847926 num_tokens/piece=5.74332\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=110665 obj=14.4403 num_tokens=883721 num_tokens/piece=7.98555\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=110479 obj=14.3843 num_tokens=884257 num_tokens/piece=8.00385\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=82857 obj=14.6248 num_tokens=929158 num_tokens/piece=11.214\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82849 obj=14.5613 num_tokens=929278 num_tokens/piece=11.2165\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=62136 obj=14.8286 num_tokens=971838 num_tokens/piece=15.6405\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=62134 obj=14.7674 num_tokens=971875 num_tokens/piece=15.6416\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46600 obj=15.0649 num_tokens=1017777 num_tokens/piece=21.8407\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46600 obj=14.9994 num_tokens=1017773 num_tokens/piece=21.8406\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34950 obj=15.335 num_tokens=1065519 num_tokens/piece=30.487\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34950 obj=15.266 num_tokens=1065518 num_tokens/piece=30.4869\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=26212 obj=15.6388 num_tokens=1115420 num_tokens/piece=42.5538\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26212 obj=15.5631 num_tokens=1115434 num_tokens/piece=42.5543\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19659 obj=15.9763 num_tokens=1169225 num_tokens/piece=59.4753\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19659 obj=15.8901 num_tokens=1169238 num_tokens/piece=59.476\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14744 obj=16.3483 num_tokens=1226829 num_tokens/piece=83.2087\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14744 obj=16.2475 num_tokens=1226874 num_tokens/piece=83.2117\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11058 obj=16.78 num_tokens=1291216 num_tokens/piece=116.768\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11058 obj=16.6633 num_tokens=1291247 num_tokens/piece=116.77\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=17.1474 num_tokens=1346923 num_tokens/piece=153.059\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=17.0423 num_tokens=1347400 num_tokens/piece=153.114\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm_unigram.vocab\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 149995 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5430559\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=2979\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 149995 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 149995\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 357808\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=73192 min_freq=83\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10912 size=20 all=115412 active=10865 piece=▁어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8938 size=40 all=119940 active=15393 piece=▁정말\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6288 size=60 all=123570 active=19023 piece=▁생\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5282 size=80 all=127600 active=23053 piece=드라마\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4218 size=100 all=130978 active=26431 piece=하게\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4185 min_freq=69\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3617 size=120 all=134384 active=9509 piece=~~\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3206 size=140 all=136919 active=12044 piece=▁좀\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2840 size=160 all=139251 active=14376 piece=^^\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2644 size=180 all=141956 active=17081 piece=▁처\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2388 size=200 al"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 3. SentencePiece 모델 학습 - unigram + bpe\n",
    "import sentencepiece as spm\n",
    "\n",
    "# Unigram\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm_unigram',\n",
    "    vocab_size=8000,\n",
    "    model_type='unigram',\n",
    "    character_coverage=1.0\n",
    ")\n",
    "\n",
    "# BPE\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm_bpe',\n",
    "    vocab_size=8000,\n",
    "    model_type='bpe',\n",
    "    character_coverage=1.0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41186951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 4. 토크나이저 로딩 및 인코딩 함수\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def encode_with_sp(model_path, texts, maxlen=50):\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.load(model_path)\n",
    "    sequences = [sp.encode(t, out_type=int) for t in texts]\n",
    "    padded = pad_sequences(sequences, padding='post', maxlen=maxlen)\n",
    "    return padded, sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4116d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 5. 텐서 변환\n",
    "X_train_uni, sp_uni = encode_with_sp(\"spm_unigram.model\", train_texts)\n",
    "X_test_uni, _ = encode_with_sp(\"spm_unigram.model\", test_texts)\n",
    "\n",
    "X_train_bpe, sp_bpe = encode_with_sp(\"spm_bpe.model\", train_texts)\n",
    "X_test_bpe, _ = encode_with_sp(\"spm_bpe.model\", test_texts)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a4ae596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 6. 모델 정의 및 학습 함수\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "def build_model(vocab_size, input_length):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, name='model'):\n",
    "    model = build_model(vocab_size=8000, input_length=X_train.shape[1])\n",
    "    print(f\"\\n📘 Training {name}...\")\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=128, validation_split=0.2, verbose=0)\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"✅ {name} Test Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8f31421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Training SentencePiece-Unigram...\n",
      "✅ SentencePiece-Unigram Test Accuracy: 0.8438\n",
      "\n",
      "📘 Training SentencePiece-BPE...\n",
      "✅ SentencePiece-BPE Test Accuracy: 0.8442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 7. 학습 및 정확도 비교\n",
    "acc_uni = train_and_evaluate(X_train_uni, y_train, X_test_uni, y_test, name=\"SentencePiece-Unigram\")\n",
    "acc_bpe = train_and_evaluate(X_train_bpe, y_train, X_test_bpe, y_test, name=\"SentencePiece-BPE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5278d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Accuracy 비교:\n",
      "• SentencePiece-Unigram: 0.8438\n",
      "• SentencePiece-BPE    : 0.8442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n📊 Accuracy 비교:\")\n",
    "print(f\"• SentencePiece-Unigram: {acc_uni:.4f}\")\n",
    "print(f\"• SentencePiece-BPE    : {acc_bpe:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddca6b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Unigram', 'BPE']\n",
    "scores = [acc_uni, acc_bpe]\n",
    "\n",
    "plt.bar(labels, scores)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.title(\"Accuracy by SentencePiece model type\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7f265",
   "metadata": {},
   "source": [
    "- Unigram과 BPE는 감성 분류 정확도에서 거의 동일한 성능을 보임.\n",
    "\n",
    "- 정확도 외에도 모델 구조, 속도, 언어적 특성(예: 한국어의 형태소 구조) 등을 종합적으로 고려해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5883d",
   "metadata": {},
   "source": [
    "### SentencePiece Unigram과 BPE 모델을 비교하여 성능 외에,\n",
    "### 모델 구조, 속도, 한국어 특성까지 종합적으로 고려한 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7b5e8",
   "metadata": {},
   "source": [
    "데이터: [Naver 영화 리뷰 감성 분석 데이터셋 (https://github.com/e9t/nsmc)] 사용\n",
    "\n",
    "토크나이징: SentencePiece (Unigram, BPE 각각 학습)\n",
    "\n",
    "모델 성능 비교: 정확도, 학습 시간, 평균 토큰 길이\n",
    "\n",
    "언어 특성 고려: 한국어 어절/형태소 기반 구조 분석 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5154839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download dataset\n",
    "\n",
    "print(\"[Step 1] Downloading NSMC dataset...\")\n",
    "\n",
    "def download_nsmc():\n",
    "    url = \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\"\n",
    "    save_path = \"nsmc_train.txt\"\n",
    "    if not os.path.exists(save_path):\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "    return save_path\n",
    "\n",
    "corpus_path = download_nsmc()\n",
    "\n",
    "print(\"[Step 1] Completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load dataset\n",
    "print(\"[Step 2] Loading dataset...\")\n",
    "\n",
    "df = pd.read_csv(corpus_path, sep='\\t').dropna()\n",
    "\n",
    "sentences = df['document'].astype(str).tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "print(f\"[Step 2] Loaded {len(sentences)} sentences.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c96f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Save corpus to file\n",
    "print(\"[Step 3] Saving corpus to corpus.txt...\")\n",
    "\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in sentences:\n",
    "        f.write(line.strip().replace('\\n', '') + '\\n')\n",
    "        \n",
    "print(\"[Step 3] Done.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train SentencePiece models\n",
    "\n",
    "def train_spm(model_type, prefix):\n",
    "    print(f\"[Step 4] Training SentencePiece model ({model_type})...\")\n",
    "    \n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input='corpus.txt',\n",
    "        model_prefix=prefix,\n",
    "        vocab_size=8000,\n",
    "        character_coverage=1.0,\n",
    "        model_type=model_type\n",
    "    )\n",
    "    print(f\"[Step 4] {model_type} model training completed.\\n\")\n",
    "\n",
    "train_spm(\"unigram\", \"spm_uni\")\n",
    "train_spm(\"bpe\", \"spm_bpe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load trained models\n",
    "print(\"[Step 5] Loading trained models...\")\n",
    "\n",
    "sp_uni = spm.SentencePieceProcessor(model_file=\"spm_uni.model\")\n",
    "sp_bpe = spm.SentencePieceProcessor(model_file=\"spm_bpe.model\")\n",
    "\n",
    "print(\"[Step 5] Models loaded.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define tokenization function\n",
    "print(\"[Step 6] Defining tokenization function...\")\n",
    "\n",
    "def tokenize_and_join(sentences, tokenizer):\n",
    "    return [\" \".join(tokenizer.encode(s, out_type=str)) for s in sentences]\n",
    "\n",
    "print(\"[Step 6] Function ready.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52564f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Split train/test data\n",
    "print(\"[Step 7] Splitting train/test data...\")\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"[Step 7] Training set: {len(X_train_raw)}, Test set: {len(X_test_raw)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Define train and evaluate function\n",
    "print(\"[Step 8] Defining training and evaluation function...\")\n",
    "\n",
    "def train_and_evaluate(tokenizer, X_train, X_test, y_train, y_test):\n",
    "    X_train_tok = tokenize_and_join(X_train, tokenizer)\n",
    "    X_test_tok = tokenize_and_join(X_test, tokenizer)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train_tok)\n",
    "    X_test_vec = vectorizer.transform(X_test_tok)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    preds = model.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    avg_len = sum(len(t.split()) for t in X_test_tok) / len(X_test_tok)\n",
    "\n",
    "    return acc, elapsed, avg_len\n",
    "\n",
    "print(\"[Step 8] Function defined.\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2722a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Run training and evaluation\n",
    "print(\"[Step 9] Running training and evaluation...\")\n",
    "\n",
    "acc_uni, time_uni, len_uni = train_and_evaluate(sp_uni, X_train_raw, X_test_raw, y_train, y_test)\n",
    "acc_bpe, time_bpe, len_bpe = train_and_evaluate(sp_bpe, X_train_raw, X_test_raw, y_train, y_test)\n",
    "\n",
    "print(\"[Step 9] Evaluation completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Display results\n",
    "print(\"[Step 10] Printing summary results...\")\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    'Model': ['Unigram', 'BPE'],\n",
    "    'Accuracy': [acc_uni, acc_bpe],\n",
    "    'Training Time (sec)': [time_uni, time_bpe],\n",
    "    'Avg Token Length': [len_uni, len_bpe]\n",
    "})\n",
    "\n",
    "print(df_result)\n",
    "print(\"[Step 10] Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Visualize results\n",
    "print(\"[Step 11] Visualizing comparison results...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "df_result.plot(x=\"Model\", y=\"Accuracy\", kind=\"bar\", ax=axes[0], title=\"Accuracy\", legend=False)\n",
    "df_result.plot(x=\"Model\", y=\"Training Time (sec)\", kind=\"bar\", ax=axes[1], title=\"Training Time\", legend=False)\n",
    "df_result.plot(x=\"Model\", y=\"Avg Token Length\", kind=\"bar\", ax=axes[2], title=\"Avg Token Length\", legend=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"[Step 11] Visualization complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
